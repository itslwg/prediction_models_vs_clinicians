% * Preamble
% ** Document settings
\documentclass{article}
% ** Packages
% load packages
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{graphics}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage[table]{xcolor}
\usepackage[T1]{fontenc}
\usepackage{float}
\usepackage{stfloats}
\usepackage{multicol}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{notoccite}
\usepackage{tabularx}
\usepackage{adjustbox}
\usepackage{pdfpages}
\captionsetup[table]{skip=10pt}
% Insert text fill colour for review reading
\newcommand{\nt}[1]{\textcolor{red}{#1}}
% ** R code
%% begin.rcode, echo = FALSE
% ## Get results list
% results <- readRDS("results.rds")
% ## Extract auc_table
% auc.tbl <- results$estimate_tables$auc_table$table_data
% ## Subset rows with CAT
% cut.lst.auc <- auc.tbl[grep("CUT", rownames(auc.tbl)),][,1]
% clin.auc <- auc.tbl[grep("Clinicians", rownames(auc.tbl)), ][1]
% ## Extract reclassification_table
% reclass.tbl <- results$estimate_tables$reclassification_table$table_data
%% end.rcode
% * Manuscript
% ** Title
\begin{document}

\title{Can prediction models triage adult trauma patients more
  accurately than clinicians?}
\maketitle
% ** Introduction
\newpage
\section{Introduction}
  
Trauma, defined as external injury in combination with the body's response, is a
major threat to population health globally. Today, about 4.5 million
people die because of trauma each year - a number that exceeds the total number
of yearly deaths from HIV/AIDS, malaria and tuberculosis combined
\cite{Abajobir2017}, calling for more research on what works and does not work in trauma
care. 

Trauma care is highly time sensitive and early identification of potentially
fatal injuries and conditions are crucial for survival
\cite{Kondo2011,Fitzgeral2015}. Therefore triage is a key component of
trauma care, and is here defined as the process of assigning different patients
different levels of urgency for treatment and investigations.

Many different trauma triage methods exist but can be broadly categorised into
triage conducted by clinicians based on patients' clinical gestalt and triage
conducted according to a priori determined criteria, regardless of whether it is
performed by clinicians or non-clinicians. The latter system may be partly or
fully based on so called prediction models.

In this context, a prediction model can be defined as an algorithm that allows
estimation of an individual patient's risk of a specific outcome, for example
mortality \cite{Collins2015}. There is an abundance of prediction models aimed
for trauma triage in the literature
\cite{LeoniedeMunteraSuzannePolinderKoenW.W.LansinkMaryseC.CnossenEwoutW.Steyerberg2017},
but no study has so far prospectively compared the performance
of clinician's triage with that of prediction models. Therefore, the aim of this
study was to evaluate and compare clinicians and prediction models in triage.
% ** Methods
% *** Study design
\section{Methods}
\subsection{Study Design}
Prospective cohort study, part of the Trauma Triage Study in India (TTRIS), a
Towards Improved Trauma Care Outcomes (TITCO) project. This study was registered
on clinicaltrials.gov, identifier NCT02838459.
% *** Setting
\subsection{Setting}
Three hospitals in urban India, KB Bhabha Hospital in Mumbai, Maulana Azad
Medical College (MAMC) in Delhi and Institute of Post Graduate Medical Education
\& Seth Sukhlal Karnani Memorial Hospital (IPGMER \& SSKM), Kolkata.
% *** Participants
% **** Eligibility criteria
\subsection{Participants}
\subsubsection{Eligibility criteria}
Any person aged $\geq$ 18 years presenting to the emergency department (ED) of
participating sites with history of trauma. History of trauma bwas here defined
as having any of the external causes of morbidity and mortality listed in
block V01-Y36, chapter XX of the International Classification of Disease
version 10 (ICD-10) codebook as primary complaint, with some exclusions
(Supplementary material).
% **** Source and methods of selection of participants and follow up
\subsubsection{Source and methods of selection of participants and
  follow up}

\begin{wrapfigure}{r}{0.55\textwidth}
  \includegraphics[scale = 0.45]{flowchart_tikz.pdf}
  \caption{Study flowchart.}
\end{wrapfigure}

The project officers worked morning, evening, and night shifts, and data was
collected from the first ten consecutive patients during their shift. A
follow-up were completed by the project officer 30 days after participant
arrived at participating hospital. The follow-up was completed in person or per
phone, depending on if the patient was still hospitalised or if the patient had
been discharged. Phone numbers of one or more contact persons, e.g. relatives,
were collected on enrollment and contacted if the participant did not reply on
follow up. Only if neither the participant nor the contact person answered any
of three repeated phone calls was the outcome recorded as missing.
% *** Variables
\subsection{Variables} 
Clinicians were instructed to categorise patients in four colour-coded
groups. The groups were green, yellow, orange, and red. Risk of
mortality were assumed to increase
moving from green to red in the corresponding colour spectrum, with
green and red respectively coded to the least and most urgent
patients.

Four prediction models (Table 1) were evaluated and compared to clinicians in
triage performance. The models included age, systolic blood pressure, heart
rate, Glasgow coma scale, AVPU, respiratory rate, and number of serious
injuries. \cite{Kondo2011, Gerdin2014, Kobusingye2000, ChampionHRSaccoWJCopesWSGannDSGennarelliTA1989} All vital signs were recorded
by the project officers, after receiving training by project management, and
overseen by local supervisors. Data on two other descriptive variables - sex and
mechanism of injury - were recorded apart from the variables included in the
models. The outcome variable was mortality within 30 days, henceforth referred
to as 30-day mortality.

% *** Statistical methods

\subsection{Statistical Methods} 
The triage ability of prediction models was first analysed by categorising
crude score output into four risk groups, similar to the
prioritisation conducted by the clinicians. Models nor clinicians were
informed of each others prioritisation. Cut-off hyperparameters
were optimised using the Area Under the Reciever Operating
Characteristics Curves (AUROCC) as performance metric in a grid
search (See subsection Discrimination). In this analyses the models are denoted RTS\textsubscript{CAT},
Gerdin et al.\textsubscript{CAT}, GAP\textsubscript{CAT}, and
KTS\textsubscript{CAT}. Then, the performance of prediction models was analysed
by treating the output as continuous, with no attempt at
standardisation. In
this analyses, models are denoted RTS\textsubscript{CON}, Gerdin et
al.\textsubscript{CON}, GAP\textsubscript{CON}, and
KTS\textsubscript{CON}. Here, the primary purpose were to conduct a
model-model comparison in order to evaluate the chosen score cut-offs.

\input{cut_points_table.tex}
  
Statistical analysis were conducted with a confidence level of 95 per cent, and
a 5 per cent level of significance. Confidence intervals were calculated using emperical
bootstrapping \cite{Efron1979}. Observations with missing data were
excluded, hence we report complete case analysis. All statistical
analysis were conducted in the R statistical environment. \cite{RDevelopmentCoreTeam2008}
% *** Discrimination 
\subsubsection{Discrimination}
Triage performance were evaluated in terms of discrimination and
reclassification. Discrimination refer to the ability to differentiate between
patients with high and low risk of the outcome of interest.
\cite{Fawcett2006}. Model discrimination may be illustrated as point True Positive Rate (TPR) and False Positive
Rate (FPR) estimates accross all possible thresholds of the models 
score. The corresponding graph is referred to as a Receiver Operating
Characteristics (ROC) curve. Discriminatory performance may be quantified by calculating the Area Under the
ROC-curves (AUROCC). An AUROCC of 0.5 indicate a discriminatory
ability no better than chance, and an AUC of 1.0 indicate perfect
discrimination. Both continous and binned scores were assessed in
order to evaluate the grid searched cut-offs.

% *** Calibration
%\subsubsection{Calibration}
%Calibration refer to the relationship between predicted and observed probability
%of mortality \cite{Knaus1991}, and is generally assessed visually by plotting
%the relationship alongside a 45-degree line originating in origo representing
%perfect calibration. However, this assessment method requires the complete model
%equation to compute predicted probabilities. Because some of the original
%studies did not report the complete model equation we were unable to compute the
%predicted probability of 30-day mortality \cite{Kobusingye2000,
%  ChampionHRSaccoWJCopesWSGannDSGennarelliTA1989, Kobusingye2000}. Instead, we
%assumed that the risk of mortality was linearly associated with risk group
%assignment, i.e. that the more severe group the higher the mortality. Thus,
%calibration was illustrated as the observed probability of 30-day mortality
%across risk groups.
% *** Reclassification 
\subsubsection{Net reclassification improvement}
Net Reclassification Improvement (NRI) may be defined as a measure of the difference in
subject classification of two models
\cite{MichaelJ.Pencina1RalphB.DAgostinoSr12009}. In this study, NRI
equals the difference of groups of summarized proportions for surviving and
non-surviving patients, each group being the sum of net proportions
reclassified up- and downwards in priority groups.
In addition to NRI, event and non-event summarized groups are assessed individually. All values range from -1 to 1, with positive values indicating the grouping
conducted by the model to be more superior than that performed by the
clinicians, and negative values indicating vice versa.

% *** Study size
\subsection{Study size}
We estimated the sample size to include a total of 200 non surviving patients,
called events, and all patients surviving during the same time period, called
non-events. This sample size was calculated based on published simulation
studies of the number of events needed to detect a difference in AUROCC between
two models of approximately < 0.05, with 80\% power and 5\% significance level,
when the prevalence of the outcome is 10\% \cite{Steyerberg2009}. To include the
first 200 non-surviving patients we identified the date when the 200th patient,
counting only complete cases, who died arrived to a participating centre. We
then included all patients, both survivors and non-survivors, who arrived before
or on this date.
% *** Ethical approvals
\subsection{Ethical approvals}
The TITCO project were granted waivers of informed consent from all
study centres. The ethical bodie's names, and approval registration
numbers, is xxxxx,
yyyyy, and IPGMER \& SSKM Research Oversight Committee (IEC/279) for
KB Bhabha Hospital, MAMC and IPGMER \& SSKM, respectively. 

\newpage
% ** Results
\section{Results}

A total of \rinline{results[["n_enrolled"]]} patients were enrolled
between 14th of July, 2016, and the 26th of July, 2017 (Table
\ref{tab:sample-characteristics}). Out of all patients,
\rinline{results$tables$raw[1, "Survivors"]}  patients survived and
\rinline{results$tables$raw[1, "Non-Survivors"]} did not survive. A
majority were \rinline{paste(results$desc_characteristics$sex,
  sep = ",")}, and the main mechanism of injury were \rinline{results$desc_characteristics$moi$Level}s, \rinline{results$desc_characteristics$moi$Value}.

AUROCC estimates and corresponding confidence intervals, as well as
confidence intervals on model-clinicians and model-model difference in AUROCC, are reported
in Table
\ref{table:auc}. \rinline{paste(names(cut.lst.auc), sep = ",")}
respectively generated AUROCCs of \rinline{paste(cut.lst.auc, sep =
  ",")}. Clinicians generates an AUROCC of \rinline{clin.auc}.

Reclassification estimates and corresponding confidence intervals for
binned model scores are reported in Table
\ref{table:reclassification}. \rinline{paste(colnames(reclass.tbl),
  sep = ",")} respectively reported an NRI of
\rinline{paste(reclass.tbl["NRI",], sep = ",")}, event
reclassification of \rinline{paste(reclass.tbl["NRI+",], soep = ",")}
and non-event reclassification of \rinline{paste(reclass.tbl["NRI-",],
  sep = ",")}.

%GAP\textsubscript{CON}, Gerdin et al.\textsubscript{CON}, and
%RTS\textsubscript{CON} had similar AUROCC as clinicians' triage, with AUROCCs of
%\rinline{tOfEstimatess[3,1]},
%\rinline{tOfEstimatess[3,2]}, and \rinline{tOfEstimatess[3,4]}, respectively. KTS\textsubscri%pt{CON} discriminated the least
%accurate with an AUROCC of \rinpline{tOfEstimatess[3,3]}.

%All patients triaged green by clinicians survived, whereas all other models had
%non-survivors among the green patients (Figure 2). Furthermore, clinicians
%performed the most consistent in their predictions, illustrated by the
%relatively straight purple graph. GAP\textsubscript{CAT} predicted higher risk
%of mortality in relation to increasing risk group, however fairly inconsistently
%as illustrated by the crooked yellow graph. Gerdin et al.\textsubscript{CAT} and KTS\textsubscript{CAT} did not categorise
%any patients as red, and no patients in the orange and red risk groups of
%RTS\textsubscript{CAT} survived.

\input{table_of_sample_characteristics.tex}
\input{auc_estimates_table.tex}
\input{reclassification_estimates_table.tex}

\begin{figure}[h!]
  \centering
  \caption{ROC-curves of, A, continous scores and, B,
    binned scores.}
  \includegraphics[scale = 0.8]{roc_plot.pdf}
\end{figure}

%Regarding reclassification, the risk-classifiction of non-surviving
%patients conducted by models were less accurate
%than that peformed by clinicians (Table 3). Compared to clinicians,
%GAP, the Gerdin et al. model, KTS and RTS respectively reclassified patients
%corresponding to net proportions of \rinline{tOfEstimatess[5,1]},
%\rinline{tOfEstimatess[5,2]}, \rinline{tOfEstimatess[5,3]}, and
%\rinline{tOfEstimatess[5,4]}. Categorisation of suriving patients, however, significantly
%improved when performed by models. According to former model order,
%the net reclassified proportions were
%\rinline{tOfEstimatess[6,1]}, \rinline{tOfEstimatess[6,2]},
%\rinline{tOfEstimatess[6,3]}, and \rinline{tOfEstimatess[6,4]}. Net
%proportions for non-events and events were combined to generate
%\rinline{tOfEstimatess[7,1]}, \rinline{tOfEstimatess[7,2]},
%\rinline{tOfEstimatess[7,3]}, and \rinline{tOfEstimatess[7,4]} in
%NRI. (Full overview in Supplementary material)

% ** Discussion
\newpage
\section{Discussion}
%The result of this study indicates clinician's triage superiority over
%RTS, the Gerdin et al. model and KTS, when compared in terms of performance in
%calibration and discrimination. Moreover, clinicians outperformed GAP in terms
%of calibration, however discriminated patients equally accurate. Clinicians
%reclassified non-surviving patients more precise than all models, though models
%categorised surviving patients more accurately than clinicians. According to the
%NRI, all models categorised patients better than clinicians.
\nt{To be written}
\nt{Visual presentation alternatives, gerdin et al. The risk of dying
  pp. 65, }
% *** Methodological considerations
\subsection{Methodological considerations}
The cut-offs used were not at the same thresholds as in the original
publications. Nor were the same number of cut points used. Some
original articles categorised patients in
three risk groups - low,
moderate, and high - yet none included a fourth
risk group. Here, the rationale were to adjust categorisation according to
existing trauma triage systems (\nt{see SATS etc.}) in order to
generalize the findings and simplify potential model implemention in
clinical practice.

Arugably as important performance estimates and illustrations as those
included,
such as precision-rcall tradeoffs, were not
generated. Insead, the aim were to follow published recommendations from clinicial
prediction model development framework (see <insert
footnote>). Calibration and clinical usefulness analyses were
omitted, however if used the former have had to be simlified, sustituting
the recommended decile scatter plot and a 0 to 1 limited x-axis for
predicted to observed outcome in each risk group. Here,
risk of 30-day mortality have had to be assumed to increase with upwards movement in
categories. The latter analysis relies on single dichtomisation, hence were not
directly applicable to this study design.

The rationale for including GAP, KTS, RTS, and the Gerdin et
al. model were, firstly, that no validation study to date have
compared the models triage performance to that of
clinicians. In contrast, few algorithms have been developed with
intuitive mobile or computer applications other than simply - a key
component in clinical implementation. 
\nt{Performance metric grid search and cut points (cat-con comparison) consideration.}

% ** Conclusion
\section{Conclusion}

\nt{To be written}

\section{Supplementary material}

\bibliographystyle{unsrt}
\bibliography{library}

\end{document}