% * Preamble
% ** Document settings
\documentclass{article}
% ** Packages
% load packages
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{graphics}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage[table]{xcolor}
\usepackage[T1]{fontenc}
\usepackage{float}
\usepackage{stfloats}
\usepackage{multicol}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{notoccite}
\usepackage{tabularx}
\usepackage{adjustbox}
\usepackage{pdfpages}
\captionsetup[table]{skip=10pt}
% Insert text fill colour for review reading
\newcommand{\nt}[1]{\textcolor{red}{#1}}
% ** R code
%% begin.rcode, echo = FALSE
% ## Get results list
% results <- readRDS("results.rds")
% ## Extract auc_table
% auc.tbl <- results$estimate_tables$auc_table$table_data
% ## Subset rows with CAT
% cut.lst.auc <- auc.tbl[grep("CUT", rownames(auc.tbl)),][,1]
% clin.auc <- auc.tbl[grep("Clinicians", rownames(auc.tbl)), ][1]
% ## Extract reclassification_table
% reclass.tbl <- results$estimate_tables$reclassification_table$table_data
%% end.rcode
% * Manuscript
% ** Title
\begin{document}

\title{Can prediction models triage adult trauma patients more
  accurately than clinicians?}
\maketitle
% ** Introduction
\newpage
\section{Introduction}
  
Trauma, defined as external injury in combination with the body's response, is a
major threat to population health globally. Today, about 4.5 million
people die because of trauma each year - a number that exceeds the total number
of yearly deaths from HIV/AIDS, malaria and tuberculosis combined
\cite{Abajobir2017}, calling for more research on what works and does not work in trauma
care. 

Trauma care is highly time sensitive and early identification of potentially
fatal injuries and conditions are crucial for survival
\cite{Kondo2011,Fitzgeral2015}. Therefore triage is a key component of
trauma care, and is here defined as the process of assigning different patients
different levels of urgency for treatment and investigations.

Many different trauma triage methods exist but can be broadly categorised into
triage conducted by clinicians based on patients' clinical gestalt and triage
conducted according to a priori determined criteria, regardless of whether it is
performed by clinicians or non-clinicians. The latter system may be partly or
fully based on so called prediction models.

In this context, a prediction model can be defined as an algorithm that allows
estimation of an individual patient's risk of a specific outcome, for example
mortality \cite{Collins2015}. There is an abundance of prediction models aimed
for trauma triage in the literature
\cite{LeoniedeMunteraSuzannePolinderKoenW.W.LansinkMaryseC.CnossenEwoutW.Steyerberg2017},
but no study has so far prospectively compared the performance
of clinician's triage with that of prediction models. Therefore, the aim of this
study was to evaluate and compare clinicians and prediction models in triage.
% ** Methods
% *** Study design
\section{Methods}
\subsection{Study Design}
Prospective cohort study, part of the Trauma Triage Study in India (TTRIS), a
Towards Improved Trauma Care Outcomes (TITCO) project. This study was registered
on clinicaltrials.gov, identifier NCT02838459.
% *** Setting
\subsection{Setting}
Three hospitals in urban India, KB Bhabha Hospital in Mumbai, Maulana Azad
Medical College (MAMC) in Delhi and Institute of Post Graduate Medical Education
\& Seth Sukhlal Karnani Memorial Hospital (IPGMER \& SSKM), Kolkata.
% *** Participants
% **** Eligibility criteria
\subsection{Participants}
\subsubsection{Eligibility criteria}
Any person aged $\geq$ 18 years presenting to the emergency department (ED) of
participating sites with history of trauma. History of trauma bwas here defined
as having any of the external causes of morbidity and mortality listed in
block V01-Y36, chapter XX of the International Classification of Disease
version 10 (ICD-10) codebook as primary complaint, with some exclusions
(Supplementary material).
% **** Source and methods of selection of participants and follow up
\subsubsection{Source and methods of selection of participants and
  follow up}

\begin{wrapfigure}{r}{0.55\textwidth}
  \includegraphics[scale = 0.45]{flowchart_tikz.pdf}
  \caption{Study flowchart.}
\end{wrapfigure}

The project officers worked morning, evening, and night shifts, and data was
collected from the first ten consecutive patients during their shift. A
follow-up were completed by the project officer 30 days after participant
arrived at participating hospital. The follow-up was completed in person or per
phone, depending on if the patient was still hospitalised or if the patient had
been discharged. Phone numbers of one or more contact persons, e.g. relatives,
were collected on enrollment and contacted if the participant did not reply on
follow up. Only if neither the participant nor the contact person answered any
of three repeated phone calls was the outcome recorded as missing.
% *** Variables
\subsection{Variables} 
Clinicians were instructed to categorise patients in four colour-coded
groups. The groups were green, yellow, orange, and red. Risk of
mortality were assumed to increase
moving from green to red in the corresponding colour spectrum, with
green and red respectively coded to the least and most urgent
patients.

Four prediction models (Table \ref{table:cut_points}) were evaluated and compared to clinicians in triage performance. The models included age, systolic blood pressure, heart
rate, Glasgow coma scale, AVPU, respiratory rate, and number of serious
injuries. \cite{Kondo2011, Gerdin2014, Kobusingye2000, ChampionHRSaccoWJCopesWSGannDSGennarelliTA1989} All vital signs were recorded
by the project officers, after receiving training by project management, and
overseen by local supervisors. Data on two other descriptive variables - sex and
mechanism of injury - were recorded apart from the variables included in the
models. The outcome variable was mortality within 30 days, henceforth referred
to as 30-day mortality.

% *** Statistical methods
\subsection{Statistical Methods} 
The triage ability of prediction models was first analysed by categorising
crude score output into four risk groups, similar to the
prioritisation conducted by the clinicians. Cut-offs
were optimised using the Area Under the Reciever Operating
Characteristics Curves (AUROCC) as performance metric in a grid
search. In this analyses the models are denoted RTS\textsubscript{CAT},
Gerdin et al.\textsubscript{CAT}, GAP\textsubscript{CAT}, and
KTS\textsubscript{CAT}. Then, the performance of prediction models was analysed
by treating the output as continuous, with no attempt at
standardisation. In
this analyses, models are denoted RTS\textsubscript{CON}, Gerdin et
al.\textsubscript{CON}, GAP\textsubscript{CON}, and
KTS\textsubscript{CON}. Here, the primary purpose were to conduct a
model\textsubscript{CAT} to model\textsubscript{CON} comparison -
henceforth referred to as a model-model analysis - in
order to evaluate the chosen score cut points. Models nor clinicians
were informed of the others prioritisation in any of the the two
analyses.

\input{cut_points_table.tex}
  
Statistical analysis were conducted with a confidence level of 95 per cent, and
a 5 per cent level of significance. Confidence intervals were calculated using emperical
bootstrapping \cite{Efron1979}. Observations with missing data were
excluded, hence we report complete case analysis. All statistical
analysis were conducted in the R statistical environment. \cite{RDevelopmentCoreTeam2008}
% *** Discrimination 
\subsubsection{Discrimination}
Triage performance were evaluated in terms of discrimination and
reclassification. Discrimination refer to the ability to differentiate between
patients with high and low risk of the outcome of interest.
\cite{Fawcett2006}. Model discrimination may be illustrated as Receiver Operating
Characteristics (ROC) curves, and discriminative performance may be quantified by calculating the Area Under the
ROC-curves (AUROCC). An AUROCC of 0.5 indicate a discriminative
ability no better than chance, and an AUC of 1.0 indicate perfect
discrimination. Both continous and binned scores were assessed in
order to evaluate the grid searched cut-offs.

% *** Reclassification

\subsubsection{Net reclassification improvement}
Net Reclassification Improvement (NRI) may be defined as a measure of the difference in
classification of two models
\cite{MichaelJ.Pencina1RalphB.DAgostinoSr12009}. In this study, NRI
equals the sum of proportions of events moving upwards and downwards in categories,
minus the sum of proportions of non-events moving upwards and downwards
in categories.
In addition to the NRI, event and non-event summed proportions are
assessed individually, respectively denoted NRI+ and NRI-. NRI, NRI+, and NRI-
values all range from -1 to 1, with positive values indicating the grouping
conducted by the model to be more superior than that performed by the
clinicians, and negative values indicating vice versa.

% *** Study size
\subsection{Study size}
We estimated the sample size to include a total of 200 non surviving patients,
called events, and all patients surviving during the same time period, called
non-events. This sample size was calculated based on published simulation
studies of the number of events needed to detect a difference in AUROCC between
two models of approximately < 0.05, with 80\% power and 5\% significance level,
when the prevalence of the outcome is 10\% \cite{Steyerberg2009}. To include the
first 200 non-surviving patients we identified the date when the 200th patient,
counting only complete cases, who died arrived to a participating centre. We
then included all patients, both survivors and non-survivors, who arrived before
or on this date.
% *** Ethical approvals
\subsection{Ethical approvals}
The TITCO project were granted waivers of informed consent from all
study centres. The ethical bodie's names, and approval registration
numbers, is xxxxx,
yyyyy, and IPGMER \& SSKM Research Oversight Committee (IEC/279) for
KB Bhabha Hospital, MAMC and IPGMER \& SSKM, respectively. 

\newpage
% ** Results
\section{Results}

A total of \rinline{results[["n_enrolled"]]} patients were enrolled
between 14th of July, 2016, and the 26th of July, 2017 (Table
\ref{tab:sample-characteristics}). Out of all patients,
\rinline{results$tables$raw[1, "Survivors"]}  patients survived and
\rinline{results$tables$raw[1, "Non-Survivors"]} did not survive. A
majority were \rinline{paste(results$desc_characteristics$sex,
  sep = ",")}, and the main mechanism of injury were \rinline{results$desc_characteristics$moi$Level}s, \rinline{results$desc_characteristics$moi$Value}.

AUROCC estimates and corresponding confidence intervals, as well as
confidence intervals on model-clinicians and model-model difference in AUROCC, are reported
in Table
\ref{table:auc}. \rinline{paste(names(cut.lst.auc), sep = ",")}
respectively generated AUROCCs of \rinline{paste(cut.lst.auc, sep =
  ",")}. Clinicians generates an AUROCC of \rinline{clin.auc}.

\nt{model-model review}

Reclassification estimates and corresponding confidence intervals for
binned model scores are reported in Table
\ref{table:reclassification}. \rinline{paste(colnames(reclass.tbl),
  sep = ",")} respectively generated an NRI of
\rinline{paste(reclass.tbl["NRI",], sep = ",")}, NRI+ of \rinline{paste(reclass.tbl["NRI+",], sep = ",")}
and NRI- of \rinline{paste(reclass.tbl["NRI-",],
  sep = ",")}.

\input{table_of_sample_characteristics.tex}
\input{auc_estimates_table.tex}
\input{reclassification_estimates_table.tex}

\begin{figure}[h!]
  \centering
  \caption{ROC-curves of, A, continous scores and, B,
    binned scores.}
  \includegraphics[scale = 0.8]{roc_plot.pdf}
\end{figure}

% ** Discussion
\newpage
\section{Discussion}
%The result of this study indicates clinician's triage superiority over
%RTS, the Gerdin et al. model and KTS, when compared in terms of performance in
%calibration and discrimination. Moreover, clinicians outperformed GAP in terms
%of calibration, however discriminated patients equally accurate. Clinicians
%reclassified non-surviving patients more precise than all models, though models
%categorised surviving patients more accurately than clinicians. According to the
%NRI, all models categorised patients better than clinicians.
\nt{To be written}

% *** Methodological considerations
\subsection{Methodological considerations}
The cut-offs used were not at the same thresholds as in some of the original
publications. Nor were the same number of cut points used. Some
original articles categorised patients in
three risk groups - low,
moderate, and high - yet none included a fourth
risk group. Here, the rationale were to adjust model categorisation according to
existing triage systems \cite{SATS} [?] in order to
simplify potential future implemention in clinical practice.

Arugably as important performance measures and illustrations as those
included,
such as precision-recall tradeoffs, were not
generated. The aim were to follow published recommendations from clinicial
prediction model development framework as far as appropriate
\cite{Steyerberg2014}. Still calibration and clinical usefulness analyses were
omitted. Observed and predicted mortality in each risk group instead
of model score deciles, and a risk group dichtomised x-axis instead of a
0 to 1 continous x-asis. In addition, one would have to assume 30-day mortality
to increase with upwards movement in categories. The latter analysis,
clinical usefulness,
relies on categorising patients in low and
high risk groups, hence were not directly applicable due to the models
multiple cut-offs.

The main rationale for including GAP, KTS, RTS, and the Gerdin et
al. model were that no validation study to date have
compared the models triage performance to that of
clinicians. However, considering a clinical usefulness aspect, other
models may be seen as more appropriate to review. One reason being
that visual presentation have been
recommended to be a highly prioritised focus area in score development and
validation in order to similify practical model use
\cite{Steyerberg2014}, and few of the algorithms included lack intuitive
charts or other form of visual aid for clinicians. Instead, most models are
represented by plain score calculators. 

\nt{Performance metric grid search and cut points (cat-con comparison) consideration.}

% ** Conclusion
\section{Conclusion}

\nt{To be written}

\section{Supplementary material}

\bibliographystyle{unsrt}
\bibliography{library}

\end{document}